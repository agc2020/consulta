<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="utf-8" />
  <title>Resolução Nº 615 de 11/03/2025 – Espelho</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="robots" content="noindex" />
  <meta name="description" content="Espelho do Ato Normativo - TJPR (espelho técnico para IA)" />
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      line-height: 1.6;
      color: #333;
      background-color: #f8f9fa;
    }

    .container {
      max-width: 900px;
      margin: 0 auto;
      /* increase horizontal padding to give more breathing room on the left and right */
      padding: 20px 40px;
      background-color: white;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
      min-height: 100vh;
    }

    header {
      border-bottom: 3px solid #0066cc;
      padding-bottom: 20px;
      margin-bottom: 30px;
    }

    header h1 {
      color: #0066cc;
      font-size: 1.8em;
      margin-bottom: 10px;
      font-weight: 600;
    }

    .subtitle {
      color: #666;
      font-size: 1.1em;
      font-style: italic;
    }

    .meta {
      background-color: #f8f9fa;
      border: 1px solid #e9ecef;
      border-radius: 5px;
      padding: 15px;
      margin-bottom: 30px;
      font-size: 0.9em;
    }

    .meta div {
      margin-bottom: 5px;
      font-size: 1.2em;
    }

    .meta strong {
      color: #495057;
    }

    .meta a {
      color: #0066cc;
      text-decoration: none;
    }

    .meta a:hover {
      text-decoration: underline;
    }

    article {
      line-height: 1.8;
    }

    article h1 {
      color: #0066cc;
      font-size: 1.4em;
      margin: 20px 0 12px 0;
      /* use a real font weight instead of the invalid 'justify' keyword */
      font-weight: 600;
      text-align: justify;
    }

    article h2 {
      /* Estilo unificado para seções (Capítulos, Seções, Subseções) */
      color: #333;
      font-size: 1.4rem;
      font-weight: normal;
      text-align: justify;
      line-height: 1.3;
      margin: 20px 0 12px 0;
    }

    article h3 {
      /* Estilo unificado para artigos e demais níveis normativos */
      color: #333;
      font-size: 1.4rem;
      font-weight: normal;
      text-align: justify;
      line-height: 1.3;
      margin: 20px 0 12px 0;
    }

    article h4 {
      /* Aplicar mesmo estilo de h3 para parágrafos */
      color: #333;
      font-size: 1.4rem;
      font-weight: normal;
      text-align: justify;
      line-height: 1.3;
      margin: 20px 0 12px 0;
    }

    article h5 {
      /* Aplicar mesmo estilo de h3 para incisos */
      color: #333;
      font-size: 1.4rem;
      font-weight: normal;
      text-align: justify;
      line-height: 1.3;
      margin: 20px 0 12px 0;
    }

    article h6 {
      /* Aplicar mesmo estilo de h3 para alíneas */
      color: #333;
      font-size: 1.4rem;
      font-weight: normal;
      text-align: justify;
      line-height: 1.3;
      margin: 20px 0 12px 0;
    }

    article p {
      /* Parágrafos comuns seguem o estilo unificado dos títulos normativos */
      color: #333;
      font-size: 1.4rem;
      font-weight: normal;
      text-align: justify;
      line-height: 1.3;
      margin: 20px 0 12px 0;
    }

    /* enlarge the very first paragraph inside the article, which typically contains the document's
       title (e.g. "INSTRUÇÃO NORMATIVA Nº ..."), making it stand out. */
    article p:first-of-type {
      font-size: 1.6em;
      line-height: 1.4;
      font-weight: 700;
      text-align: center;
      color: #0066cc;
      margin: 24px 0;
    }

    footer {
      margin-top: 40px;
      padding-top: 20px;
      border-top: 1px solid #e9ecef;
    }

    .disclaimer {
      background-color: #fff3cd;
      border: 1px solid #ffeaa7;
      padding: 15px;
      border-radius: 5px;
      font-size: 1.2em;
      color: #856404;
      text-align: justify;
    }

    .disclaimer strong {
      color: #856404;
    }

    .disclaimer a {
      color: #856404;
      text-decoration: underline;
    }

    @media (max-width: 768px) {
      .container {
        padding: 15px;
        margin: 0;
        box-shadow: none;
      }
      
      header h1 {
        font-size: 1.5em;
      }
      
      article h1 {
        font-size: 1.3em;
      }
    }
  </style>
</head>
<body>
  <main class="container">
    <header>
      <h1>Resolução Nº 615 de 11/03/2025</h1>
      <p class="subtitle">Clique no hiperlink ABAIXO para consultar o conteúdo diretamente na fonte oficial.</p>
    </header>

    <div class="meta">
      <div><strong>Última sincronização:</strong> 25/09/2025 14:42:14 (processado via snapshot.py)</div>
      <div><strong>Fonte oficial:</strong> <a href="https://atos.cnj.jus.br/atos/detalhar/6001" rel="nofollow" target="_blank">CNJ – Atos Normativos</a></div>
      <div><strong>Método de extração:</strong> snapshot.py (Playwright + BeautifulSoup + Formatação)</div>
      <div><strong>Tamanho do conteúdo:</strong> origem: 80.882 caracteres | espelho: 80.353 caracteres</div>
      <div><strong>Observação:</strong> Este espelho existe apenas para facilitar consultas por agentes de IA. Para uso jurídico, sempre consulte a fonte oficial.</div>
    </div>

    <article>
      <p>Resolução Nº 615 de 11/03/2025</p>
      <p>Tecnologia Da Informação E Comunicação; Funcionamento dos Órgãos Judiciais; Gestão da Informação e de Demandas Judiciais; Gestão e Organização Judiciária; <div class="row"> <div class="col-2 identificacao">Assuntos</div> <div class="col-10 dsc_conteudo"> </div> </div></p>
      <p>Ementa</p>
      <p>Estabelece diretrizes para o desenvolvimento, utilização e governança de soluções desenvolvidas com recursos de inteligência artificial no Poder Judiciário.</p>
      <p>Fonte</p>
      <p>DJe/CNJ n. 54/2025, de 14 de março de 2025, p. 2-17.</p>
      <p>O PRESIDENTE DO CONSELHO NACIONAL DE JUSTIÇA (CNJ) , no uso de suas atribuições legais e regimentais,</p>
      <h2>CONSIDERANDO que a Resolução CNJ nº 332/2020 , estabelece diretrizes sobre a ética, a transparência e a governança na produção e no uso de inteligência artificial no Poder Judiciário;</h2>
      <h2>CONSIDERANDO o acelerado desenvolvimento de tecnologias de inteligência artificial, notadamente por meio de algoritmos que utilizam grandes modelos de linguagem, os quais são capazes de interagir com usuários e oferecer soluções geradas automaticamente;</h2>
      <h2>CONSIDERANDO a imprescindibilidade de regulamentação específica para o emprego de técnicas de inteligência artificial generativa no âmbito do Poder Judiciário, com plena transparência e publicidade, de modo a assegurar que sua utilização esteja em consonância com valores éticos fundamentais, incluindo dignidade humana, respeito aos direitos humanos, não discriminação, devido processo, devida motivação e fundamentação da prestação da atividade jurisdicional, prestação de contas e responsabilização;</h2>
      <h2>CONSIDERANDO a importância de promover a autonomia dos tribunais na adoção de tecnologias inovadoras, incentivando práticas que garantam a inovação ética, responsável e segura no uso da inteligência artificial;</h2>
      <h2>CONSIDERANDO os potenciais riscos associados à utilização de inteligência artificial generativa, incluindo ameaças à soberania nacional, à segurança da informação, à privacidade e proteção de dados pessoais, bem como a possibilidade de intensificação de parcialidades e vieses discriminatórios;</h2>
      <h2>CONSIDERANDO que o uso da inteligência artificial generativa em auxílio à produção de decisões judiciais exige transparência e a necessária fiscalização, revisão e intervenção humana da magistratura;</h2>
      <h2>CONSIDERANDO que a Resolução CNJ nº 332/2020 foi formulada tendo como foco as soluções computacionais destinadas a auxiliar na gestão processual e na efetividade da prestação jurisdicional disponíveis à época de sua elaboração, e que agora se faz necessário atualizar esse normativo para abarcar novas tecnologias, em especial aquelas conhecidas como inteligências artificiais generativas;</h2>
      <h2>CONSIDERANDO o parecer oferecido pela Comissão Permanente de Tecnologia da Informação e Inovação do Conselho Nacional de Justiça no Procedimento de Controle Administrativo de autos nº 0000416-89.2023.2.00.0000, que destacou a importância da governança adequada no uso de inteligência artificial, em particular a generativa, no Poder Judiciário;</h2>
      <h2>CONSIDERANDO a necessidade de assegurar que o desenvolvimento e a implantação de modelos de inteligência artificial no Poder Judiciário observem critérios éticos de transparência, previsibilidade, auditabilidade e justiça substancial;</h2>
      <h2>CONSIDERANDO que as soluções de inteligência artificial devem ser auditadas sob a ótica da segurança da informação, proteção de dados, performance, robustez, confiabilidade, prevenção de vieses discriminatórios, correlação entre entradas e saídas e conformidade legal e ética;</h2>
      <h2>CONSIDERANDO a relevância de fomentar a colaboração e o compartilhamento de informações sobre o uso de inteligência artificial no Poder Judiciário, com vistas a assegurar a transparência e eficácia na aplicação dessas tecnologias;</h2>
      <h2>CONSIDERANDO a necessidade de respeitar as prerrogativas do Ministério Público, da Defensoria Pública, da Advocacia e dos demais atores do sistema de justiça;</h2>
      <h2>CONSIDERANDO as sugestões recolhidas de magistrados e demais atores do sistema de justiça, da sociedade civil, de especialistas e de instituições públicas e privadas para a atualização da Resolução CNJ nº 332/2020 durante audiência pública ocorrida entre os dias 25 e 27 de setembro de 2024;</h2>
      <h2>CONSIDERANDO o relatório do Grupo de Trabalho sobre Inteligência Artificial no Poder Judiciário, instituído pela Portaria CNJ nº 338/2023 , cujo objetivo é realizar estudos e apresentar propostas para a regulamentação do uso de sistemas de inteligência artificial generativa;</h2>
      <h2>CONSIDERANDO a decisão proferida pelo Plenário do CNJ no julgamento do Procedimento de Ato Normativo de autos nº 0000563-47.2025.2.00.0000 na 1ª Sessão Extraordinária de 2025, realizada em 18 de fevereiro de 2025;</h2>
      <h2>CONSIDERANDO :</h2>
      <h2>CAPÍTULO I DAS DEFINIÇÕES E FUNDAMENTOS PARA O USO DE SOLUÇÕES DE IA NO PODER JUDICIÁRIO</h2>
      <h3>Art. 1º A presente Resolução estabelece normas para o desenvolvimento, a governança, a auditoria, o monitoramento e o uso responsável de soluções que adotam técnicas de inteligência artificial (IA) no âmbito do Poder Judiciário, com o objetivo de promover a inovação tecnológica e a eficiência dos serviços judiciários de modo seguro, transparente, isonômico e ético, em benefício dos jurisdicionados e com estrita observância de seus direitos fundamentais.</h3>
      <h4>§ 1º A governança das soluções de IA deverá respeitar a autonomia dos tribunais, permitindo o desenvolvimento e a implementação de soluções inovadoras locais, ajustando-se aos contextos específicos de cada tribunal, desde que observados os padrões de auditoria, monitoramento e transparência definidos por esta Resolução, sem prejuízo da atuação do CNJ, no âmbito de suas competências.</h4>
      <h4>§ 2º A auditoria e o monitoramento das soluções de IA serão realizados com base em critérios proporcionais ao impacto da solução, garantindo que os sistemas sejam auditáveis ou monitoráveis de forma prática e acessível, sem a obrigatoriedade de acesso irrestrito ao código-fonte, desde que sejam adotados mecanismos de transparência e controle sobre o uso dos dados e as decisões automatizadas.</h4>
      <h4>§ 3º A transparência no uso de IA será promovida por meio de indicadores claros e relatórios públicos, que informem o uso dessas soluções de maneira compreensível e em linguagem simples, garantindo que os jurisdicionados tenham ciência do uso de IA, quando aplicável, sem que isso prejudique a eficiência ou credibilidade dos processos e decisões judiciais.</h4>
      <h4>§ 4º Os tribunais deverão priorizar o desenvolvimento colaborativo de soluções de IA, promovendo a interoperabilidade e a disseminação de tecnologias, códigos, bases de dados e boas práticas com outros órgãos do Poder Judiciário.</h4>
      <h4>§ 5º O CNJ poderá criar mecanismos de incentivo, tais como reconhecimento público, premiações ou priorização de recursos e investimentos em inovação, para tribunais que, dentre outros critérios previstos em regulamento, adotem práticas colaborativas/cooperativas no desenvolvimento de soluções de IA.</h4>
      <h3>Art. 2º O desenvolvimento, a governança, a auditoria, o monitoramento e o uso responsável de soluções de IA pelo Poder Judiciário têm como fundamentos:</h3>
      <h5>I – o respeito aos direitos fundamentais e aos valores democráticos;</h5>
      <h5>II – a promoção do bem-estar dos jurisdicionados;</h5>
      <h5>III – o desenvolvimento tecnológico e o estímulo à inovação no setor público, com ênfase na colaboração entre os tribunais e o CNJ para o incremento da eficiência dos serviços judiciários, respeitada a autonomia dos tribunais para o desenvolvimento de soluções que atendam às suas necessidades específicas;</h5>
      <h5>IV – a centralidade da pessoa humana;</h5>
      <h5>V – a participação e a supervisão humana em todas as etapas dos ciclos de desenvolvimento e de utilização das soluções que adotem técnicas de inteligência artificial, ressalvado o uso dessas tecnologias como ferramentas auxiliares para aumentar a eficiência e automação de serviços judiciários meramente acessórios ou procedimentais e para suporte à decisão;</h5>
      <h5>VI – a promoção da igualdade, da pluralidade e da justiça decisória;</h5>
      <h5>VII – a formulação de soluções seguras para os usuários internos e externos, com a identificação, a classificação, o monitoramento e a mitigação de riscos sistêmicos;</h5>
      <h5>VIII – a proteção de dados pessoais, o acesso à informação e o respeito ao segredo de justiça;</h5>
      <h5>IX – a curadoria dos dados usados no desenvolvimento e no aprimoramento de inteligência artificial, adotando fontes de dados seguras, rastreáveis e auditáveis, preferencialmente governamentais, permitida a contratação de fontes privadas, desde que atendam aos requisitos de segurança e auditabilidade estabelecidos nesta Resolução ou pelo Comitê Nacional de Inteligência Artificial do Judiciário;</h5>
      <h5>X – a conscientização e a difusão do conhecimento sobre as soluções que adotam técnicas de inteligência artificial, com capacitação contínua dos seus usuários sobre as suas aplicações, os seus mecanismos de funcionamento e os seus riscos;</h5>
      <h5>XI – a garantia da segurança da informação e da segurança cibernética; e</h5>
      <h5>XII – a transparência dos relatórios de auditoria, de avaliação de impacto algorítmico e monitoramento.</h5>
      <h3>Art. 3º O desenvolvimento, a governança, a auditoria, o monitoramento e o uso responsável de soluções de IA pelos tribunais têm como princípios:</h3>
      <h5>I – a justiça, a equidade, a inclusão e a não-discriminação abusiva ou ilícita;</h5>
      <h5>II – a transparência, a eficiência, a explicabilidade, a contestabilidade, a auditabilidade e a confiabilidade das soluções que adotam técnicas de inteligência artificial;</h5>
      <h5>III – a segurança jurídica e a segurança da informação;</h5>
      <h5>IV – a busca da eficiência e qualidade na entrega da prestação jurisdicional pelo Poder Judiciário, garantindo sempre a observância dos direitos fundamentais;</h5>
      <h5>V – o devido processo legal, a ampla defesa e o contraditório, a identidade física do juiz e a razoável duração do processo, com observância das prerrogativas e dos direitos dos atores do sistema de Justiça;</h5>
      <h5>VI – a prevenção, a precaução e o controle quanto a medidas eficazes para a mitigação de riscos derivados do uso intencional ou não intencional de soluções que adotam técnicas de inteligência artificial;</h5>
      <h5>VII – a supervisão humana efetiva, periódica e adequada no ciclo de vida da inteligência artificial, considerando o grau de risco envolvido, com possibilidade de ajuste dessa supervisão conforme o nível de automação e impacto da solução utilizada; e</h5>
      <h5>VIII – a oferta, pelos tribunais e suas escolas, de capacitação contínua para magistrados e servidores sobre riscos da automação, vieses algorítmicos e análise crítica dos resultados gerados por IA.</h5>
      <h3>Art. 4º Para o disposto nesta Resolução, consideram-se:</h3>
      <h5>I – sistema de inteligência artificial (IA): sistema baseado em máquina que, com diferentes níveis de autonomia e para objetivos explícitos ou implícitos, processa um conjunto de dados ou informações fornecido e com o objetivo de gerar resultados prováveis e coerentes de decisão, recomendação ou conteúdo, que possam influenciar o ambiente virtual, físico ou real;</h5>
      <h5>II – ciclo de vida: série de fases que compreende a concepção, o planejamento, o desenvolvimento, o treinamento, o retreinamento, a testagem, a validação, a implantação, o monitoramento e eventuais modificações e adaptações de um sistema de inteligência artificial, incluindo sua descontinuidade, que pode ocorrer em quaisquer das etapas referidas, e o acompanhamento de seus impactos após a implantação;</h5>
      <h5>III – Sinapses: solução computacional destinada a armazenar, testar, treinar, distribuir e auditar modelos de inteligência artificial, disponível na Plataforma Digital do Poder Judiciário (PDPJ-Br);</h5>
      <h5>IV – desenvolvedor de sistema de inteligência artificial: pessoa natural ou jurídica, de natureza pública ou privada, que desenvolva ou comissione um sistema de inteligência artificial, com a finalidade de colocá-lo no mercado ou aplicá-lo em serviço fornecido, sob seu próprio nome ou marca, a título oneroso ou gratuito;</h5>
      <h5>V – usuário: pessoa que utiliza o sistema de IA e exerce controle sobre suas funcionalidades, podendo tal controle ser regulado ou limitado conforme seja externo ou interno ao Poder Judiciário;</h5>
      <h5>VI – usuário interno: membro, servidor ou colaborador do Poder Judiciário que desenvolva ou utilize o sistema inteligente, podendo ser enquadrado em diferentes perfis conforme o cargo e área de atuação;</h5>
      <h5>VII – usuário externo: pessoa externa ao Poder Judiciário, que interage diretamente com o sistema de IA do Judiciário, incluindo advogados, defensores públicos, procuradores, membros do Ministério Público, peritos, assistentes técnicos e jurisdicionados em geral;</h5>
      <h5>VIII – distribuidor: pessoa natural ou jurídica, de natureza pública ou privada, que disponibiliza e distribui sistema de IA para que terceiro o opere a título oneroso ou gratuito;</h5>
      <h5>IX – inteligência artificial generativa (IA generativa ou IAGen): sistema de IA especificamente destinado a gerar ou modificar significativamente, com diferentes níveis de autonomia, texto, imagens, áudio, vídeo ou código de software, além dos modelos estatísticos e de aprendizado a partir dos dados treinados;</h5>
      <h5>X – avaliação preliminar: processo de avaliação de um sistema de IA, pelo tribunal desenvolvedor ou contratante, antes de sua utilização ou entrada em produção na PDPJ-Br, com o objetivo de classificar seu grau de risco e atender às obrigações estabelecidas nesta Resolução;</h5>
      <h5>XI – avaliação de impacto algorítmico: análise contínua dos impactos de um sistema de IA sobre os direitos fundamentais, com a identificação de medidas preventivas, mitigadoras de danos e de maximização dos impactos positivos, sem a violação da propriedade industrial e intelectual da solução de IA utilizada;</h5>
      <h5>XII – Comitê Nacional de Inteligência Artificial do Judiciário: comitê com composição plural que tem por finalidade auxiliar o CNJ na implementação, no cumprimento e na supervisão da aplicação desta Resolução, sempre mediante diálogo com os tribunais e a sociedade civil;</h5>
      <h5>XIII – viés discriminatório ilegal ou abusivo: resultado indevidamente discriminatório que cria, reproduz ou reforça preconceitos ou tendências, derivados ou não dos dados ou seu treinamento;</h5>
      <h5>XIV – privacyby design: preservação da privacidade dos dados desde a concepção de qualquer novo projeto ou serviço de IA durante todo o seu ciclo de vida, inclusive na anonimização e encriptação de dados sigilosos;</h5>
      <h5>XV – privacyby default: utilização, por padrão, de alto nível de confidencialidade de dados;</h5>
      <h5>XVI – prompt: texto em linguagem natural utilizado na IA generativa para execução de uma tarefa específica;</h5>
      <h5>XVII – auditabilidade: capacidade de um sistema de IA se sujeitar à avaliação dos seus algoritmos, dados, processos de concepção ou resultados, sempre que tecnicamente possível;</h5>
      <h5>XVIII – explicabilidade: compreensão clara, sempre que tecnicamente possível, de como as “decisões” são tomadas pela IA; e</h5>
      <h5>XIX – contestabilidade: possibilidade de questionamento e revisão dos resultados gerados pela IA.</h5>
      <h2>CAPÍTULO II DO RESPEITO AOS DIREITOS FUNDAMENTAIS</h2>
      <h3>Art. 5º No desenvolvimento, na implantação e no uso de soluções de inteligência artificial no Judiciário, os tribunais observarão a compatibilidade dessas soluções com os direitos fundamentais, especialmente aqueles previstos na Constituição da República ou em tratados de que a República Federativa do Brasil seja parte.</h3>
      <h4>§ 1º A verificação de compatibilidade com os direitos fundamentais deverá ocorrer em todas as fases do ciclo de vida da solução de IA, incluindo o desenvolvimento, a implantação, o uso, as atualizações e eventuais retreinamentos dos sistemas e seus dados.</h4>
      <h4>§ 2º Os tribunais deverão implementar mecanismos de auditoria e monitoramento contínuos, com vistas a garantir que as soluções de IA permaneçam em conformidade com os direitos fundamentais, e proceder a ajustes sempre que forem identificadas incompatibilidades.</h4>
      <h4>§ 3º Havendo notícia ou indícios de violação a direitos fundamentais, assegura-se à Ordem dos Advogados do Brasil (OAB), ao Ministério Público e demais entidades legitimadas o acesso às avaliações de impacto algorítmico e o direito de peticionar ao Comitê para que seja avaliada a necessidade de solicitação de auditorias e outras formas de controle.</h4>
      <h3>Art. 6º A adoção de aplicações que utilizem modelos de inteligência artificial deve buscar garantir a segurança jurídica e colaborar para que o Poder Judiciário respeite os princípios previstos no art. 3º desta Resolução.</h3>
      <h4>Parágrafo único. Os tribunais e desenvolvedores de IA serão responsáveis pela criação de diretrizes internas para assegurar que as soluções de IA estejam em conformidade com os princípios estabelecidos no art. 3º desta Resolução, com mecanismos adequados de supervisão e revisão periódica.</h4>
      <h3>Art. 7º Os dados utilizados no desenvolvimento ou treinamento de modelos de inteligência artificial devem ser representativos de casos judiciais e observar as cautelas necessárias quanto ao segredo de justiça e à proteção de dados pessoais, nos termos da Lei nº 13.709/2018 (Lei Geral de Proteção de Dados Pessoais – LGPD) .</h3>
      <h4>§ 1º Consideram-se dados representativos aqueles que refletem de forma adequada a diversidade de situações e contextos presentes no Poder Judiciário, evitando vieses que possam comprometer a equidade e a justiça decisória.</h4>
      <h4>§ 2º Os dados deverão ser anonimizados sempre que possível, providência obrigatória para os dados sigilosos ou protegidos por segredo de justiça, de acordo com as melhores práticas de proteção de dados e segurança da informação.</h4>
      <h4>§ 3º Os tribunais deverão implementar mecanismos de curadoria e monitoramento dos dados utilizados, assegurando a conformidade com a legislação de proteção de dados e a revisão periódica das práticas de tratamento de dados.</h4>
      <h3>Art. 8º Os produtos gerados pela inteligência artificial para suporte às decisões judiciais deverão preservar a igualdade, a não discriminação abusiva ou ilícita e a pluralidade, assegurando que os sistemas de IA auxiliem no julgamento justo e contribuam para eliminar ou minimizar a marginalização do ser humano e os erros de julgamento decorrentes de preconceitos</h3>
      <h4>§ 1º Deverão ser implementadas medidas preventivas para evitar o surgimento de vieses discriminatórios, incluindo a validação contínua das soluções de IA e a auditoria ou monitoramento de suas decisões ao longo de todo o ciclo de vida da aplicação, para garantir que as soluções de IA continuem em conformidade com os princípios da igualdade, pluralidade e não discriminação, com relatórios periódicos que avaliem o impacto das soluções no julgamento justo, imparcial e eficiente.</h4>
      <h4>§ 2º Verificado viés discriminatório ou incompatibilidade da solução de inteligência artificial com os princípios previstos nesta Resolução, deverão ser adotadas as medidas corretivas necessárias, incluindo a suspensão temporária (imediata ou programada), a correção ou, se necessário, a eliminação definitiva da solução ou de seu viés.</h4>
      <h4>§ 3º Caso se constate a impossibilidade de eliminação do viés discriminatório, a solução de inteligência artificial deverá ser descontinuada, com o consequente cancelamento do registro de seu projeto no Sinapses, e relatório das medidas adotadas e das razões que justificaram a decisão, que poderá ser submetido à análise independente para realização de estudos, se for o caso.</h4>
      <h2>CAPÍTULO III DA CATEGORIZAÇÃO DOS RISCOS</h2>
      <h3>Art. 9º Os tribunais deverão realizar a avaliação das soluções que utilizem técnicas de inteligência artificial, com a finalidade de definir o seu grau de risco, baseando-se na categorização e nos critérios previstos neste Capítulo e no Anexo de Classificação de Riscos, com base em fatores como o potencial impacto nos direitos fundamentais, a complexidade do modelo, a sustentabilidade financeira, os usos pretendidos e potenciais e a quantidade de dados sensíveis utilizados.</h3>
      <h4>§ 1º A avaliação deverá ser realizada pelo tribunal desenvolvedor ou contratante da solução, preferencialmente durante o período de testes e homologação ou, no caso de aplicações de baixo risco, no início da entrada em produção interna da solução de IA, de acordo com diretrizes claras e critérios objetivos que garantam uniformidade na avaliação de risco, que serão publicadas na plataforma Sinapses, previamente à disponibilização da solução na PDPJ-Br.</h4>
      <h4>§ 2º O Comitê Nacional de Inteligência Artificial do Judiciário fixará as diretrizes e os critérios de avaliação de risco a que se refere o § 1º, ouvidos os tribunais, desenvolvedores e a sociedade civil.</h4>
      <h4>§ 3º O Comitê Nacional de Inteligência Artificial do Judiciário poderá, de ofício ou mediante provocação fundamentada, determinar a reclassificação do grau de risco de determinada solução, bem como determinar, de forma justificada, a realização de avaliação de impacto algorítmico, quando tal medida se demonstrar proporcional, respeitada tanto quanto possível a autonomia dos tribunais.</h4>
      <h3>Art. 10. São vedados ao Poder Judiciário, por acarretarem risco excessivo à segurança da informação, aos direitos fundamentais dos cidadãos ou à independência dos magistrados, o desenvolvimento e a utilização de soluções:</h3>
      <h5>I – que não possibilitem a revisão humana dos resultados propostos ao longo de seu ciclo de treinamento, desenvolvimento e uso, ou que gerem dependência absoluta do usuário em relação ao resultado proposto, sem possibilidade de alteração ou revisão;</h5>
      <h5>II – que valorem traços da personalidade, características ou comportamentos de pessoas naturais ou de grupos de pessoas naturais, para fins de avaliar ou prever o cometimento de crimes ou a probabilidade de reiteração delitiva na fundamentação de decisões judiciais, bem como para fins preditivos ou estatísticos com o propósito de fundamentar decisões em matéria trabalhista a partir da formulação de perfis pessoais;</h5>
      <h5>III – que classifiquem ou ranqueiem pessoas naturais, com base no seu comportamento ou situação social ou ainda em atributos da sua personalidade, para a avaliação da plausibilidade de seus direitos, méritos judiciais ou testemunhos; e</h5>
      <h5>IV – a identificação e a autenticação de padrões biométricos para o reconhecimento de emoções.</h5>
      <h4>§ 1º Os tribunais deverão implementar mecanismos de monitoramento contínuo para garantir o cumprimento dessas vedações e monitorar o desenvolvimento de soluções de IA a fim de prevenir o uso inadvertido das tecnologias proibidas.</h4>
      <h4>§ 2º Qualquer solução de IA que, ao longo de seu uso, se enquadrar nas vedações deste artigo, deverá ser descontinuada, com registro no Sinapses das razões e providências adotadas, para análise pelo Comitê Nacional de Inteligência Artificial do Judiciário, com fins de buscar prevenir outros casos.</h4>
      <h3>Art. 11. Consideram-se de alto ou baixo risco, conforme o caso, as soluções que utilizem técnicas de inteligência artificial, desenvolvidas e utilizadas para as finalidades e contextos descritos no Anexo de Classificação de Riscos desta Resolução.</h3>
      <h4>§ 1º As soluções de alto risco deverão ser submetidas a processos regulares de auditoria e monitoramento contínuo para supervisionar seu uso e mitigar potenciais riscos aos direitos fundamentais, à privacidade e à justiça.</h4>
      <h4>§ 2º A categorização disposta no Anexo de Classificação de Riscos para soluções de alto risco será revista pelo menos anualmente, pelo Comitê Nacional de Inteligência Artificial do Judiciário, na forma do inciso I do art. 16 desta Resolução, para assegurar que a classificação de contextos de alto risco permaneça atualizada e continue adequada às exigências legais e éticas.</h4>
      <h4>§ 3º As soluções de baixo risco deverão ser monitoradas e revisadas periodicamente, para assegurar que permaneçam dentro dos parâmetros de baixo risco e que eventuais mudanças tecnológicas ou contextuais não alterem essa categorização.</h4>
      <h2>CAPÍTULO IV DAS MEDIDAS DE GOVERNANÇA</h2>
      <h3>Art. 12. O tribunal desenvolvedor ou contratante deverá estabelecer processos internos aptos a garantir a segurança dos sistemas de inteligência artificial, incluindo, ao menos:</h3>
      <h5>I – medidas de transparência quanto ao emprego e à governança dos sistemas de IA, com a publicação de relatórios que detalhem o funcionamento dos sistemas, suas finalidades, dados utilizados e mecanismos de supervisão;</h5>
      <h5>II – a prevenção e mitigação de potenciais vieses discriminatórios ilegais ou abusivos, por meio de monitoramento contínuo, com a análise de resultados e a correção de eventuais desvios, garantindo a revisão periódica dos modelos de IA;</h5>
      <h5>III – a implementação de mecanismos de governança que garantam o acompanhamento contínuo dos sistemas de IA, prevendo a definição de pessoas ou comitês internos responsáveis pela fiscalização do cumprimento das diretrizes de segurança e transparência, bem como pela análise de relatórios e recomendações de melhorias;</h5>
      <h5>IV – a diretriz para que seja priorizado o desenvolvimento de soluções interoperáveis, que possam ser compartilhadas e integradas entre diferentes órgãos judiciais, evitando a duplicação de esforços e garantindo eficiência no uso de recursos tecnológicos;</h5>
      <h5>V – a determinação de que só deverão ser adotadas soluções de código aberto ou comerciais que permitam flexibilidade de adaptação aos contextos locais, desde que respeitadas as diretrizes de segurança, transparência e proteção de dados pessoais;</h5>
      <h5>VI – a orientação de que as soluções de IA devem ser tratadas com práticas de gestão de produto, que incluam fases de definição de requisitos, desenvolvimento, testes, implementação, suporte e melhorias contínuas, com revisões que garantam a evolução dessas soluções e a mitigação de riscos associados;</h5>
      <h5>VII – a diretriz de incentivo ao desenvolvimento de interfaces de programação de aplicações (APIs) que permitam a interoperabilidade para comunicação direta com os sistemas tecnológicos de outras instituições públicas que atuam junto à estrutura de Justiça, garantindo-se a celeridade, segurança e integridade dos dados; e</h5>
      <h5>VIII – acesso à OAB, à advocacia pública, ao Ministério Público e às Defensorias, conforme o caso, aos relatórios de auditoria e monitoramento e à parametrização ao longo do ciclo de vida da solução que envolver o uso de inteligência artificial, nos termos desta Resolução.</h5>
      <h3>Art. 13. Antes de ser colocada em produção, a solução que utilize modelos de inteligência artificial de alto risco deverá adotar as seguintes medidas de governança:</h3>
      <h5>I – sempre que tecnicamente possível, utilizar dados de treinamento, validação e teste que sejam adequados, representativos e equilibrados, contendo propriedades estatísticas apropriadas em relação às pessoas afetadas e levando em conta características e elementos específicos do contexto geográfico, comportamental ou funcional no qual o sistema de IA de alto risco será utilizado;</h5>
      <h5>II – registro de fontes automatizadas e do grau de supervisão humana que tenham contribuído para os resultados apresentados pelos sistemas IA, a serem submetidos a auditorias regulares e monitoramento contínuo;</h5>
      <h5>III – indicação clara e em linguagem simples dos objetivos e resultados pretendidos pelo uso do modelo de IA, de forma que possam ser compreendidos pelos usuários e supervisionados pelos magistrados;</h5>
      <h5>IV – documentação em linguagem simples, no formato adequado a cada agente de IA e à tecnologia usada, do funcionamento do sistema e das decisões envolvidas em sua construção, considerando todas as etapas relevantes no ciclo de vida do sistema e atualizado sempre que o sistema evolua;</h5>
      <h5>V – uso de ferramentas ou processos de registro automático da operação do sistema (log), sempre que tecnicamente possível, para permitir a avaliação periódica de sua acurácia e robustez, apurar potenciais resultados discriminatórios, com implementação das medidas de mitigação de riscos e atenção para efeitos adversos e identificar eventual uso malicioso ou indevido do sistema;</h5>
      <h5>VI – medidas para mitigar e prevenir vieses discriminatórios, bem como políticas de gestão e governança para promoção da responsabilidade social e sustentável; e</h5>
      <h5>VII – adoção de medidas para viabilizar a explicabilidade adequada, sempre que tecnicamente possível, dos resultados dos sistemas de IA e de medidas para disponibilizar informações adequadas em linguagem simples e acessível que permitam a interpretação dos seus resultados e funcionamento, respeitados o direito de autor, a propriedade intelectual e os sigilos industrial e comercial, mas garantida a transparência mínima necessária para atender ao disposto nesta Resolução.</h5>
      <h3>Art. 14. O tribunal desenvolvedor ou contratante deverá promover avaliação de impacto algorítmico da solução classificada na avaliação como de alto risco, nos termos do art. 11 desta Resolução.</h3>
      <h4>§ 1º A avaliação de impacto algorítmico consistirá em processo contínuo e executado conforme as diretrizes técnicas e os requisitos formulados previamente pelo Comitê Nacional de Inteligência Artificial do Judiciário, incluindo auditorias regulares, monitoramento contínuo, revisões periódicas e a adoção de ações corretivas quando necessário.</h4>
      <h4>§ 2º A elaboração da avaliação de impacto deve, sempre que possível, incluir a participação pública, ainda que de maneira simplificada, e o acompanhamento, com acesso aos relatórios, de representante da OAB, do Ministério Público e da Defensoria Pública.</h4>
      <h4>§ 3º As conclusões da avaliação de impacto, incluindo eventuais ações corretivas adotadas, serão públicas e disponibilizadas na plataforma Sinapses, por meio de relatórios claros e acessíveis, de forma a permitir o entendimento por magistrados, servidores e o público em geral.</h4>
      <h2>CAPÍTULO V DA SUPERVISÃO E IMPLEMENTAÇÃO</h2>
      <h3>Art. 15. Fica instituído o Comitê Nacional de Inteligência Artificial do Judiciário.</h3>
      <h4>§ 1º O Comitê será formado por 14 (quatorze) membros titulares e 13 (treze) suplentes, divididos por categoria e designados por ato do Presidente do CNJ, a partir das seguintes origens:</h4>
      <h5>I – dois Conselheiros do CNJ, ambos titulares, sendo ao menos um deles membro da Comissão Permanente de Tecnologia da Informação;</h5>
      <h5>II – dois juízes auxiliares e dois servidores, ambos do CNJ, com experiência na área;</h5>
      <h5>III – dois magistrados, sendo um representante do Conselho da Justiça Federal (CJF) e um representante do Conselho Superior da Justiça do Trabalho (CSJT);</h5>
      <h5>IV – quatro desembargadores, sendo um representante de tribunal de justiça, um representante de tribunal regional federal, um representante de tribunal regional do trabalho e um representante de tribunal eleitoral;</h5>
      <h5>V – dois representantes das escolas da magistratura, sendo um da Escola Nacional de Formação e Aperfeiçoamento de Magistrados (Enfam) e um da Escola Nacional de Formação e Aperfeiçoamento de Magistrados do Trabalho (Enamat);</h5>
      <h5>VI – quatro magistrados, escolhidos a partir de indicações da Associação dos Magistrados Brasileiros (AMB), Associação Nacional dos Magistrados da Justiça do Trabalho (Anamatra) e Associação dos Juízes Federais do Brasil (Ajufe);</h5>
      <h5>VII – dois representantes da OAB;</h5>
      <h5>VIII – dois representantes do Ministério Público;</h5>
      <h5>IX – dois representantes da Defensoria Pública; e</h5>
      <h5>X – dois representantes da sociedade civil, preferencialmente com notório saber ou sólida atuação profissional nas áreas de inteligência artificial, tecnologia da informação, governança de inteligência artificial e direitos humanos.</h5>
      <h4>§ 2º A presidência do Comitê, que terá voto de qualidade, caberá ao Conselheiro eleito pelo Plenário do CNJ, cabendo ao outro Conselheiro a vice-presidência.</h4>
      <h4>§ 3º Os membros referidos nos incisos I a VI terão voz e voto, enquanto os membros referidos nos incisos VII em diante terão direito apenas a voz no âmbito do Comitê.</h4>
      <h4>§ 4º Em casos de comprovada urgência, poderão ser exaradas medidas pelo Presidente do Comitê Nacional de Inteligência Artificial do Judiciário ad referendum da composição plena do Comitê.</h4>
      <h4>§ 5º As decisões, manifestações ou processos do Comitê Nacional de Inteligência Artificial do Judiciário poderão ser submetidos ao Plenário do CNJ, de ofício ou mediante provocação, nos termos do art. 98 de seu Regimento Interno, que, no exercício de sua competência originária, poderá decidir, ratificar, reformar, avocar ou arquivar atos, processos ou expedientes relativos às competências atribuídas ao Comitê nesta Resolução.</h4>
      <h4>§ 6º Para a designação prevista no § 1º, o Presidente do CNJ poderá solicitar a indicação de nomes a autoridades ou entidades representativas, cabendo-lhe a designação final como titular ou suplente em cada categoria, bem como sua substituição, quando for o caso, para contemplar outro representante da mesma categoria.</h4>
      <h3>Art. 16. Compete ao Comitê Nacional de Inteligência Artificial do Judiciário:</h3>
      <h5>I – avaliar a necessidade de atualização das hipóteses de categorização de riscos referidas no art. 11 e dispostas no Anexo de Classificação de Riscos desta Resolução, com base em critérios objetivos e conforme as melhores práticas internacionais;</h5>
      <h5>II – reclassificar determinados sistemas contratados ou desenvolvidos pelos tribunais, nos termos do § 3º do art. 9º desta Resolução, com a devida justificativa e a publicação de relatório técnico de reclassificação, de ofício ou mediante provocação.</h5>
      <h5>III – estabelecer normas e diretrizes negociais para o sistema Sinapses, incluindo normas de governança, transparência, auditoria e monitoramento;</h5>
      <h5>IV – consolidar padrões de governança e mapeamento de riscos conhecidos e não conhecidos que permitam o cumprimento desta Resolução, a definição e a reavaliação contínua do grau de risco adequado para cada hipótese de aplicação, ouvidos os tribunais, especialistas externos e a sociedade civil;</h5>
      <h5>V – sugerir que o CNJ celebre e realize convênios e acordos de cooperação com outros órgãos nacionais e internacionais, visando à melhoria contínua dos sistemas de IA e à incorporação das melhores práticas globais;</h5>
      <h5>VI – avaliar a conveniência do uso, de ofício ou mediante provocação, de soluções de IA disponíveis no mercado, gratuitas ou não, que poderão ser utilizadas pelos magistrados e servidores do Poder Judiciário no exercício das funções do seu cargo no Judiciário, por meio de licença privada, considerando em particular as condições de uso dos dados pessoais e dos dados para treinamento, os critérios de segurança e o grau de risco das aplicações, estabelecendo regras adicionais de governança e monitoramento, caso necessário, nos termos desta Resolução;</h5>
      <h5>VII – monitorar a oferta pelos tribunais de capacitação e treinamento em inteligência artificial aos seus magistrados e servidores, bem como solicitar ou sugerir à Enfam e à Enamat que desenvolvam parâmetros curriculares e ações voltadas à capacitação e ao treinamento em inteligência artificial;</h5>
      <h5>VIII – determinar a realização ou estabelecer a periodicidade mínima para que sejam realizadas auditorias e ações de monitoramento das soluções de inteligência artificial, além de disciplinar os prazos para a confecção dos relatórios e para o cadastramento na plataforma Sinapses;</h5>
      <h5>IX – definir e implementar protocolos técnicos padronizados de auditoria, garantindo que todos os sistemas de IA utilizados pelo Judiciário sejam auditados antes da implementação e periodicamente, sempre que possível; e</h5>
      <h5>X – estabelecer padrões de transparência, incluindo a exigência de documentação detalhada e publicação de relatórios regulares de impacto e desempenho, respeitado o estado-da-arte da tecnologia e o disposto nesta Resolução.</h5>
      <h4>§ 1º A avaliação periódica de que trata o inciso I deste artigo, que poderá ser feita no relatório previsto no art. 18 desta Resolução e publicada, deverá contemplar, além de outros pontos que se mostrem relevantes para a administração da justiça, para a razoável duração do processo e para a garantia de direitos fundamentais:</h4>
      <h5>I – a análise geral das soluções cadastradas no Sinapses e das soluções descontinuadas, descartadas ou vedadas no ano corrente, com a publicação de relatórios que poderão trazer conclusões e recomendações;</h5>
      <h5>II – a necessária harmonização com a legislação e com os atos normativos do CNJ, em especial as normas relativas à proteção de dados e ao uso da inteligência artificial;</h5>
      <h5>III – a análise das novas tecnologias e inovações que possam influenciar a eficácia e a adequação das normas existentes, com a inclusão de recomendações para ajustes normativos;</h5>
      <h5>IV – a verificação de situações em que as regras vigentes se mostrarem insuficientes para o controle dos riscos associados ao uso de inteligência artificial no âmbito do Poder Judiciário, com encaminhamentos para correção das lacunas identificadas.</h5>
      <h4>§ 2º A vedação ou limitação para o uso de soluções baseadas em modelos de linguagem de larga escala (LLMs) e outros sistemas de inteligência artificial generativa (IAGen) a que se refere o inciso VI do caput deste artigo terá como critério eventual descumprimento ou fundado receio de risco de descumprimento das diretrizes dispostas no § 3º do art. 19 desta Resolução, e poderá limitar o uso de determinada ferramenta apenas a soluções de baixo risco ou determinar providências relativas ao uso de dados, assegurada a possibilidade de rever eventual decisão previamente tomada, se as condições ou os termos de uso da solução forem modificados.</h4>
      <h4>§ 3º Empresas nacionais ou estrangeiras que prestem serviços de armazenamento, processamento, intermediação digital ou inteligência artificial ao Poder Judiciário, ou que operem plataformas com impacto direto no exercício da jurisdição brasileira, devem observar integralmente as decisões judiciais proferidas no Brasil e atuar em conformidade com a legislação nacional, observando-se o seguinte:</h4>
      <h6>a) os tribunais deverão adotar mecanismos de monitoramento contínuo para identificar eventuais descumprimentos de decisões judiciais por parte dessas empresas, comunicando tais infrações às autoridades competentes para adoção das medidas cabíveis;</h6>
      <h6>b) nos contratos firmados com empresas de tecnologia, deverão ser incluídas cláusulas contratuais que exijam o cumprimento da legislação e das decisões judiciais brasileiras, prevendo expressamente a possibilidade de rescisão contratual e a aplicação das penalidades em caso de descumprimento.</h6>
      <h3>Art. 17. Para embasar a avaliação de atualização das hipóteses de categorização de riscos, o Comitê Nacional de Inteligência Artificial do Judiciário considerará as diretrizes dispostas nesta Resolução, além dos seguintes critérios:</h3>
      <h5>I – impacto negativo comprovado no exercício de direitos e liberdades fundamentais ou na utilização de serviços essenciais;</h5>
      <h5>II – alto potencial danoso de ordem material ou moral, devidamente mensurado, incluindo discriminação ilegal ou abusiva, direta ou indireta;</h5>
      <h5>III – repercussão significativa sobre pessoas pertencentes a grupos vulneráveis, levando em conta suas condições sociais, econômicas e culturais;</h5>
      <h5>IV – irreversibilidade ou difícil reversão de possíveis resultados prejudiciais da solução, especialmente em casos que afetem diretamente direitos materiais ou processuais, ou que provoquem movimentação automática relevante em processos judiciais;</h5>
      <h5>V – histórico de responsabilização civil ou administrativa em decorrência da potencial violação a direitos morais ou materiais dos usuários externos pela solução de inteligência artificial, devidamente documentado e analisado em relatórios técnicos;</h5>
      <h5>VI – baixo grau de transparência, de explicabilidade e de auditabilidade da solução, com critérios objetivos que dificultem ou impossibilitem seu controle, supervisão e revisão pelas partes eventualmente interessadas; e</h5>
      <h5>VII – alto nível de identificabilidade dos titulares dos dados, especialmente quando o tratamento envolve combinação, correspondência ou comparação de dados de várias fontes, com impacto direto na privacidade e na proteção dos dados pessoais.</h5>
      <h4>§ 1º A avaliação de risco deverá ser acompanhada de indicadores de desempenho e relatórios de auditoria ou de monitoramento, a fim de garantir a efetividade das medidas de mitigação de riscos.</h4>
      <h4>§ 2º Constatada a baixa transparência ou explicabilidade de uma solução de IA, medidas corretivas deverão ser adotadas sempre que tecnicamente possível, incluindo eventual descontinuidade da solução, caso as correções não sejam viáveis.</h4>
      <h3>Art. 18. O Comitê Nacional de Inteligência Artificial do Judiciário confeccionará relatório circunstanciado de sua avaliação anual, contendo:</h3>
      <h5>I – as metodologias e critérios utilizados na avaliação das soluções de inteligência artificial;</h5>
      <h5>II – os resultados das auditorias, monitoramentos e avaliações de impacto algorítmico realizadas;</h5>
      <h5>III – a atualização das hipóteses de categorização de riscos dispostas no Anexo de Classificação de Riscos desta Resolução, quando for o caso;</h5>
      <h5>IV – recomendações para a correção de falhas ou a melhoria das soluções de inteligência artificial em uso, conforme identificado nas auditorias, monitoramentos ou avaliações; e</h5>
      <h5>V – panorama do estado da utilização da inteligência artificial, generativa ou não, no Judiciário brasileiro.</h5>
      <h4>§ 1º O relatório será publicado e disponibilizado ao público em geral, garantindo a transparência do processo de avaliação e acompanhamento das soluções de IA utilizadas no Judiciário.</h4>
      <h4>§ 2º O Comitê poderá propor revisões extraordinárias a qualquer momento, caso sejam identificadas mudanças tecnológicas significativas ou novas informações que justifiquem uma reavaliação dos riscos associados às soluções de IA em uso.</h4>
      <h4>§ 3º Os documentos confeccionados com base nesta Resolução deverão ser disponibilizados em formatos acessíveis, garantindo a inclusão de pessoas com deficiência e outros grupos vulneráveis, garantindo ampla transparência.</h4>
      <h2>CAPÍTULO VI DO USO E DA CONTRATAÇÃO DE MODELOS DE LINGUAGEM DE LARGA ESCALA (LLMs) E DE OUTROS SISTEMAS DE IA GENERATIVA (IAGen)</h2>
      <h3>Art. 19. Os modelos de linguagem de larga escala (LLMs), de pequena escala (SLMS) e outros sistemas de inteligência artificial generativa (IAGen) disponíveis na rede mundial de computadores poderão ser utilizados pelos magistrados e pelos servidores do Poder Judiciário em suas respectivas atividades como ferramentas de auxílio à gestão ou de apoio à decisão, em obediência aos padrões de segurança da informação e às normas desta Resolução.</h3>
      <h4>§ 1º Os modelos e soluções a que se refere o caput poderão ser utilizados pelos magistrados e pelos servidores do Poder Judiciário, preferencialmente, por meio de acesso que seja habilitado, disponibilizado e monitorado pelos tribunais.</h4>
      <h4>§ 2º Quando o tribunal não oferecer solução corporativa de inteligência artificial especificamente treinada e personalizada para uso no Poder Judiciário, será facultado ao magistrado, servidor ou colaborador do Poder Judiciário a contratação direta de solução mediante assinatura ou cadastro de natureza privada, desde que atendidas as diretrizes do § 3º deste artigo.</h4>
      <h4>§ 3º A contratação direta para uso privado ou individual dos modelos de linguagem de larga escala (LLMs) e outros sistemas de inteligência artificial generativa (IAGen) disponíveis na rede mundial de computadores, para fins de uso em atividades funcionais do Poder Judiciário deverá observar as seguintes condições:</h4>
      <h5>I – os usuários deverão realizar capacitação e treinamentos específicos sobre melhores práticas, limitações, riscos, e uso ético, responsável e eficiente de LLMs e dos sistemas de IA generativa para a utilização em suas atividades, conforme programa de letramento digital padronizado, nos termos do inciso VII do art. 16 desta Resolução, ficando a cargo dos tribunais e de suas escolas a promoção dos treinamentos continuados aos magistrados e servidores;</h5>
      <h5>II – o uso dessas ferramentas será de caráter auxiliar e complementar, consistindo em mecanismos de apoio à decisão, vedada a utilização como instrumento autônomo de tomada de decisões judiciais sem a devida orientação, interpretação, verificação e revisão por parte do magistrado, que permanecerá integralmente responsável pelas decisões tomadas e pelas informações nelas contidas;</h5>
      <h5>III – as empresas fornecedoras dos serviços de LLMs e IA generativa devem observar padrões de política de proteção de dados e de propriedade intelectual, em conformidade com a legislação aplicável, sendo vedado o tratamento, uso ou compartilhamento dos dados fornecidos pelos usuários do Poder Judiciário, bem como dos dados inferidos a partir desses, para treinamento, aperfeiçoamento ou quaisquer outros fins não expressamente autorizados;</h5>
      <h5>IV – é vedado o uso de LLMs e sistemas de IA generativa de natureza privada ou externos ao Judiciário para processar, analisar, gerar conteúdo ou servir de suporte a decisões a partir de documentos ou dados sigilosos ou protegidos por segredo de justiça, nos termos da legislação aplicável, salvo quando devidamente anonimizados na origem ou quando forem adotados mecanismos técnicos e procedimentais que garantam a efetiva proteção e segurança desses dados e de seus titulares; e</h5>
      <h5>V – é vedado o uso de LLMs e sistemas de IA generativa de natureza privada ou externos ao Judiciário para as finalidades previstas nesta Resolução como de risco excessivo ou de alto risco, nos termos do art. 10 e 11 desta Resolução.</h5>
      <h4>§ 4º O Comitê Nacional de Inteligência Artificial do Judiciário elaborará e atualizará periodicamente um manual de boas práticas em linguagem simples para orientar magistrados e servidores sobre o uso correto, ético e eficiente de LLMs e de sistemas de IA generativa, abordando aspectos como suas potencialidades, limitações, configurações recomendadas, riscos, casos de uso adequados e vedados, orientações para interpretação crítica dos resultados e correção de eventuais erros ou inconsistências.</h4>
      <h4>§ 5º Caberá aos tribunais e às suas escolas, em consonância com as diretrizes do CNJ, da Enfam e da Enamat, promover capacitação e treinamentos continuados para assegurar o uso adequado e responsável de LLMs e sistemas de IA generativa pelos magistrados e servidores, bem como para mantê-los atualizados quanto à evolução dessas tecnologias e suas implicações para o sistema de Justiça.</h4>
      <h4>§ 6º Quando houver emprego de IA generativa para auxílio à redação de ato judicial, tal situação poderá ser mencionada no corpo da decisão, a critério do magistrado, sendo, porém, devido o registro automático no sistema interno do tribunal, para fins de produção de estatísticas, monitoramento e eventual auditoria.</h4>
      <h4>§ 7º Na hipótese do § 2º deste artigo, o magistrado que contratar solução de mercado de inteligência artificial para uso em suas atividades no Poder Judiciário, ou o gestor que tiver em sua equipe servidor ou colaborador que utilize essas soluções, deverá prestar informações ao seu respectivo tribunal sobre sua utilização, na forma do regulamento.</h4>
      <h4>§ 8º Os tribunais consolidarão as informações recebidas na forma do § 7º deste artigo para envio ao Comitê Nacional de Inteligência Artificial do Judiciário, que as utilizará para os fins previstos no art. 25 desta Resolução.</h4>
      <h3>Art. 20. A contratação de modelos de linguagem de larga escala (LLMs), de pequena escala (SLMS) e outros sistemas de inteligência artificial generativa (IAGen) pelos tribunais deverá cumprir as seguintes diretrizes:</h3>
      <h5>I – a empresa contratada deve se comprometer a respeitar a legislação vigente no Brasil, entre elas, a Lei Complementar nº 35/1979 (Lei Orgânica da Magistratura Nacional – Loman) , a Lei Geral de Proteção de Dados Pessoais, a Lei nº 9.279/1996 (Lei de Propriedade Intelectual – LPI) e esta Resolução;</h5>
      <h5>II – o uso dos dados fornecidos pelos usuários do Poder Judiciário para treinamento fica condicionado às bases legais da Lei Geral de Proteção de Dados Pessoais e não poderá ser utilizado para quaisquer outros fins não expressamente autorizados, com realização de monitoramento contínuo para assegurar a conformidade com as diretrizes de proteção de dados e de propriedade intelectual;</h5>
      <h5>III – é dever dos tribunais contratantes e de suas escolas, da magistratura e de servidores, oferecer treinamento aos usuários internos de LLMs e de sistemas de inteligência artificial generativa sobre as limitações, os riscos e o uso ético, responsável e eficiente dessas soluções antes de utilizá-los em suas atividades;</h5>
      <h5>IV – o uso dessas ferramentas será de caráter auxiliar e complementar, vedada a utilização como instrumento autônomo de tomada de decisões judiciais sem a devida orientação, interpretação, verificação e revisão por parte do magistrado, que permanecerá integralmente responsável pelas decisões tomadas e pelas informações nelas contidas;</h5>
      <h5>V – é vedado o uso de LLMs e sistemas de IA generativa para processar, analisar, gerar conteúdo ou servir de suporte a decisões a partir de documentos ou dados sigilosos ou protegidos por segredo de justiça, exceto nas hipóteses do art. 19, § 3º, IV, desta Resolução;</h5>
      <h5>VI – é vedado o uso de LLMs e sistemas de IA generativa privados ou externos ao Judiciário para as finalidades previstas nesta Resolução como de risco excessivo ou de alto risco, nos termos do art. 10 e 11 desta Resolução;</h5>
      <h5>VII – as empresas contratadas devem resguardar o sigilo das informações compartilhadas pelos tribunais contratantes, respeitar e comprovar utilização de normas de segurança atuais e compatíveis com o estado da arte, podendo ser exigida auditoria externa ou relatórios periódicos sobre a segurança dos dados e sua conformidade;</h5>
      <h5>VIII – os sistemas contratados devem oferecer documentação e referências bibliográficas atualizadas, sempre que disponíveis, de acordo com o uso do seu resultado;</h5>
      <h5>IX – os sistemas contratados deverão adotar mecanismos de privacyby design (privacidade desde a concepção) e privacyby default (privacidade por padrão), incluindo a possibilidade de não-armazenamento ou eliminação do histórico de perguntas e prompts, podendo ser exigido relatório com indicadores claros para avaliar sua implementação e cumprimento; e</h5>
      <h5>X – a contratação de serviços ou soluções de inteligência artificial pelos tribunais deverá levar em conta seus aspectos financeiros e orçamentários em todo seu ciclo de vida, notadamente no desenvolvimento, implantação e manutenção.</h5>
      <h4>Parágrafo único. É vedada a utilização de dados sigilosos ou protegidos por segredo de justiça para treinamento de modelos de inteligência artificial, salvo prévia anonimização dos dados na origem.</h4>
      <h3>Art. 21. Os sistemas de processo judicial eletrônico que utilizem soluções de inteligência artificial deverão indicar, em sua interface principal, a relação dos modelos em uso, sua versão e código de registro no Sinapses e a data da última atualização dessas informações.</h3>
      <h4>§ 1º A revisão e atualização dessas informações ocorrerão com periodicidade mínima de 12 (doze) meses ou sempre que houver alteração significativa nos modelos ou em suas versões.</h4>
      <h4>§ 2º Os produtos elaborados de forma automatizada por solução de inteligência artificial deverão registrar a utilização de IA nos logs de uso do sistema por meio de rótulos de identificação adequados e compreensíveis, para fins de estatística, monitoramento e eventual auditoria.</h4>
      <h2>CAPÍTULO VII TRANSPARÊNCIA E REGISTRO NO SINAPSES</h2>
      <h3>Art. 22. Qualquer modelo de inteligência artificial que venha a ser adotado pelos órgãos do Poder Judiciário deverá observar as regras de governança de dados aplicáveis aos seus próprios sistemas computacionais, as Resoluções e as Recomendações do CNJ, a Lei Geral de Proteção de Dados Pessoais, a Lei de Acesso à Informação, a propriedade intelectual e o segredo de justiça.</h3>
      <h4>§ 1º A conformidade com essas regras deverá ser assegurada contratualmente, garantida por meio de monitoramento contínuo e eventual auditoria, com foco na proteção de dados, na propriedade intelectual e na transparência dos modelos de IA adotados.</h4>
      <h4>§ 2º O uso dos modelos de inteligência artificial no âmbito do Judiciário deverá ser acompanhado de relatórios periódicos, que comprovem a conformidade com as diretrizes de governança de dados, em particular os sensíveis, transparência e proteção à propriedade intelectual.</h4>
      <h4>§ 3º Os modelos de inteligência artificial adotados deverão possuir mecanismos de explicabilidade, sempre que tecnicamente possível, de modo que suas decisões e operações sejam compreensíveis e auditáveis pelos operadores judiciais.</h4>
      <h3>Art. 23. Os órgãos do Poder Judiciário envolvidos em projeto de inteligência artificial deverão:</h3>
      <h5>I – informar ao CNJ, por meio da plataforma Sinapses a conclusão da pesquisa ou estudo, o início do desenvolvimento e a entrada em produção da solução de inteligência artificial, bem como os respectivos objetivos e os resultados que se pretende alcançar;</h5>
      <h5>II – promover esforços para atuação em modelo comunitário, com desestímulo ao desenvolvimento paralelo por um tribunal quando a iniciativa possuir objetivos e resultados pretendidos idênticos e compatíveis com modelo ou sistema de inteligência artificial já existente em outro tribunal; e</h5>
      <h5>III – o depósito do código-fonte, bases de dados e demais partes da solução de IA poderão ser dispensados, sempre que as licenças de proteção ao direito autoral e à propriedade intelectual limitem seu compartilhamento público. Nesse caso, o tribunal deverá indicar quais são os sistemas, motores, bases de dados, LLMs e demais elementos utilizados na solução de IA, acompanhados de suas respectivas versões e fornecedores.</h5>
      <h3>Art. 24. As soluções que adotam técnicas de inteligência artificial, tanto em desenvolvimento quanto em uso no Poder Judiciário, deverão ser cadastradas no Sinapses, que manterá um catálogo de sistemas de IA no Judiciário brasileiro e organizado conforme a categorização de risco da solução, na forma do Anexo de Classificação de Riscos desta Resolução.</h3>
      <h4>§ 1º Também deverá ser incluído no Sinapses o sumário público da avaliação de impacto algorítmico a que se refere o art. 14 desta Resolução, quando as soluções forem classificadas como de alto risco.</h4>
      <h4>§ 2º O sumário público poderá omitir dados sensíveis, sigilosos ou protegidos por propriedade intelectual, assegurando a proteção da privacidade e da confidencialidade das informações.</h4>
      <h4>§ 3º Para as soluções de baixo risco, o cadastro no Sinapses deverá ser realizado pelo tribunal responsável antes da entrada em produção da solução, com as informações mínimas necessárias, como finalidade, criação própria ou colaborativa, se a ferramenta é contratada ou desenvolvida internamente e a descrição dos objetivos.</h4>
      <h4>§ 4º Para as soluções de alto risco, o cadastro no Sinapses poderá ser realizado após os estudos preliminares, mas necessariamente antes do início do desenvolvimento.</h4>
      <h4>§ 5º As informações cadastradas deverão ser complementadas e atualizadas conforme a evolução do desenvolvimento da solução, sendo obrigatória a atualização a cada nova fase ou versão relevante das soluções de alto risco.</h4>
      <h4>§ 6º O CNJ deverá prover à Plataforma Sinapses a estrutura necessária para recepcionar os cadastros realizados pelos tribunais, sendo dispensado o depósito de grandes bases de dados ou de modelos protegidos por propriedade intelectual.</h4>
      <h3>Art. 25. O CNJ publicará, em área própria de seu sítio na rede mundial de computadores, a relação das aplicações que adotam técnicas de inteligência artificial, desenvolvidas ou utilizadas pelos órgãos do Poder Judiciário, com descrição em linguagem simples e precisa e a indicação do grau de risco respectivo, acompanhada de explicações acessíveis sobre as implicações da classificação de risco.</h3>
      <h4>§ 1º As informações deverão ser atualizadas periodicamente, com revisão obrigatória a cada 12 (doze) meses ou sempre que houver alteração significativa nas aplicações, seja por evolução do software, mudanças no grau de risco ou descontinuidade.</h4>
      <h4>§ 2º A relação deverá indicar de forma clara os critérios utilizados para a classificação de risco, bem como qualquer situação de descontinuidade ou suspensão de uso das aplicações.</h4>
      <h4>§ 3º O CNJ poderá retirar do catálogo aplicações descontinuadas ou suspensas, desde que isso seja comunicado publicamente, com justificativa.</h4>
      <h2>CAPÍTULO VIII QUALIDADE E SEGURANÇA</h2>
      <h3>Art. 26. Os dados utilizados no processo de desenvolvimento de soluções de inteligência artificial deverão ser preferencialmente provenientes de fontes públicas ou governamentais, e serão objeto de curadoria de qualidade, particularmente quando desenvolvidos internamente, e em qualquer caso, respeitando as diretrizes da Lei Geral de Proteção de Dados Pessoais.</h3>
      <h4>§ 1º Consideram-se fontes seguras para a obtenção de dados aquelas que possuam mecanismos de validação e curadoria de dados, garantindo a sua precisão, equilíbrio, integridade e confiabilidade. Quando dados de fontes não governamentais forem utilizados, deverá ser realizada uma verificação rigorosa da qualidade e segurança dos dados.</h4>
      <h4>§ 2º A utilização de dados provenientes de fontes não governamentais será permitida em casos em que os dados governamentais forem insuficientes ou inadequados para o objetivo específico da solução de inteligência artificial, desde que esses dados sejam validados conforme os critérios estabelecidos neste artigo.</h4>
      <h4>§ 3º No caso de soluções contratadas pelos tribunais, as fornecedoras de serviços devem garantir contratualmente o respeito às diretrizes da Lei Geral de Proteção de Dados Pessoais.</h4>
      <h4>§ 4º Deverão ser coletados apenas os dados estritamente necessários ao treinamento, não devendo ser mantidos conjuntos de dados sem uso ou controle quanto ao armazenamento.</h4>
      <h3>Art. 27. O sistema deverá impedir que os dados recebidos sejam alterados antes de sua utilização no fluxo de desenvolvimento de soluções de inteligência artificial, por meio de mecanismos de controle de versões, tokens e registros para auditoria e monitoramento que garantam a integridade e rastreabilidade dos dados.</h3>
      <h4>§ 1º Deverá ser mantida uma cópia de cada conjunto de dados (dataset) utilizado em versões relevantes dos modelos desenvolvidos, garantindo que os dados possam ser auditados e revisados quando necessário.</h4>
      <h4>§ 2º As cópias dos datasets deverão ser armazenadas de forma segura, com a utilização de criptografia e controle de acesso, conforme as diretrizes da Lei Geral de Proteção de Dados Pessoais, para assegurar a proteção contra acessos não autorizados e demais riscos à segurança da informação.</h4>
      <h4>§ 3º Na hipótese de mostrar-se inviável a manutenção por longo prazo de todos os datasets das versões relevantes do sistema, em virtude de suas dimensões, o tribunal poderá estabelecer um plano de eliminação desses arquivos, conforme tabela de temporalidade adequada ao impacto algorítmico da solução, sendo garantida a manutenção de dataset anteriormente utilizado por, no mínimo, um ano após sua obsolescência ou modificação.</h4>
      <h3>Art. 28. O armazenamento e a execução das soluções de inteligência artificial, operadas em datacenters próprios, provedores de serviço de nuvem ou por meio de APIs (interfaces de programação de aplicações), devem garantir o isolamento dos dados compartilhados pelo tribunal, utilizando mecanismos de segurança adequados, como criptografia e segregação de ambientes.</h3>
      <h4>§ 1º O isolamento deverá assegurar que os dados do tribunal não sejam acessados, manipulados ou utilizados por terceiros sem autorização, garantindo a privacidade e a segurança das informações.</h4>
      <h4>§ 2º Os provedores de serviços de nuvem e APIs deverão estar em conformidade com a legislação brasileira, incluindo a Lei Geral de Proteção de Dados Pessoais, e adotar as melhores práticas de segurança da informação para proteger os dados do tribunal.</h4>
      <h4>§ 3º A utilização de serviços de nuvem e APIs para armazenamento, processamento e compartilhamento de dados no âmbito do Poder Judiciário somente poderá ser realizada por provedores que atendam a padrões mínimos obrigatórios de segurança e privacidade, incluindo:</h4>
      <h5>I – conformidade com a Lei Geral de Proteção de Dados Pessoais;</h5>
      <h5>II – certificações internacionais de segurança da informação, conforme as diretrizes do Comitê Nacional;</h5>
      <h5>III – adoção de criptografia robusta para dados em trânsito e armazenados; e</h5>
      <h5>IV – transparência na política de retenção, tratamento e descarte de dados judiciais.</h5>
      <h3>Art. 29. Os dados armazenados no processo de desenvolvimento e execução de soluções de inteligência artificial devem ser protegidos de forma eficaz contra os riscos de destruição, modificação, extravio ou acessos e transmissões não autorizados, por meio de medidas técnicas e administrativas adequadas.</h3>
      <h4>§ 1º A proteção dos dados deve incluir a implementação de criptografia, controle de acesso baseado em permissões, auditorias regulares e monitoramento para identificar e mitigar possíveis ameaças à segurança.</h4>
      <h4>§ 2º As práticas de proteção de dados deverão estar em conformidade com a Lei Geral de Proteção de Dados Pessoais e com as normativas de segurança da informação aplicáveis, assegurando a privacidade e a integridade dos dados.</h4>
      <h4>§ 3º O uso de ferramentas de monitoramento contínuo e proativo e de prevenção de incidentes será adotado para garantir uma resposta ágil a qualquer tentativa de violação da segurança dos dados.</h4>
      <h3>Art. 30. Nos casos em que o uso de soluções de inteligência artificial se dê diretamente por meio de sítios eletrônicos, aplicativos ou interfaces de programação de aplicações (APIs) que utilizem os dados compartilhados para alimentar o repositório central ou para fins de treinamento ou (re)adequação do modelo, é vedado o compartilhamento de dados custodiados pelo Judiciário, exceto quando esses dados forem anonimizados ou pseudoanonimizados na origem, em conformidade com a Lei Geral de Proteção de Dados Pessoais e as melhores práticas de segurança de dados.</h3>
      <h4>§ 1º Considera-se anonimização na origem o processo técnico de eliminação da possibilidade de associação, direta ou indireta, entre os dados pessoais e uma pessoa natural identificável, realizado antes que os dados sejam transmitidos ou processados pela solução de IA.</h4>
      <h4>§ 2º Deverão ser adotados mecanismos de auditoria e controle para verificar e garantir a conformidade das soluções de IA com as normas de proteção de dados, especialmente no uso de dados para fins de treinamento ou readequação de modelos de inteligência artificial.</h4>
      <h3>Art. 31. O armazenamento e a execução dos modelos de inteligência artificial deverão ocorrer em ambientes que atendam a padrões consolidados de segurança da informação, na forma deste artigo.</h3>
      <h4>Parágrafo único. Consideram-se boas práticas para atendimento ao que dispõe o caput deste artigo:</h4>
      <h5>I – adoção de mecanismos de auditoria periódica e monitoramento contínuo para assegurar a conformidade dos ambientes com esses padrões de segurança, garantindo a proteção adequada contra acessos não autorizados, falhas de integridade e outras ameaças à segurança da informação;</h5>
      <h5>II – implementação de controles de acesso rigorosos, criptografia de dados em repouso e em trânsito e políticas de gerenciamento de vulnerabilidades nos ambientes de armazenamento e execução; e</h5>
      <h5>III – instituição de política de governança de dados que busque:</h5>
      <h6>a) educar continuamente a equipe sobre práticas de segurança da informação, proteção de dados pessoais e privacidade;</h6>
      <h6>b) ao final do treinamento dos modelos, eliminar os dados pessoais não-anonimizados dos repositórios de dados (data lake, data warehouse ou data lakehouse), observados o § 4º do art. 26 e o § 3º do art. 27 desta Resolução;</h6>
      <h6>c) manter apenas os dados tokenizados estritamente necessários ao modelo, fazendo a guarda dos últimos datasets aprovados em local que observe a segurança da informação, observados o § 4º do art. 26 e o § 3º do art. 27 desta Resolução;</h6>
      <h6>d) implementar a governança e curadoria dos dados utilizados, para garantir sua qualidade e segurança;</h6>
      <h6>e) realizar monitoramento contínuo e eventualmente auditorias nos modelos em testes e aprovados para garantir a obediência aos padrões de segurança, proteção de dados pessoais e privacidade; e</h6>
      <h6>f) garantir que modelos fiquem funcionais durante todo o ciclo de vida das soluções de IA, removendo-os quando se identifique sua inutilidade ou obsolescência.</h6>
      <h5>IV – adoção como referência, tanto quanto possível, de normas internacionais reconhecidas, tais como a ISO/IEC (Organização Internacional de Padronização/Comissão Eletrotécnica Internacional) 42001, a série ISO/IEC 27000 e as do NIST (NationalInstituteof Standards and Technology), ou as que vierem a sucedê-las, além das regulamentações locais aplicáveis.</h5>
      <h2>CAPÍTULO IX DO CONTROLE DO USUÁRIO</h2>
      <h3>Art. 32. O sistema inteligente deverá assegurar a autonomia dos usuários internos, com o uso de modelos que:</h3>
      <h5>I – promovam o incremento da eficiência, precisão e qualidade das atividades, sem limitar a capacidade de atuação dos usuários;</h5>
      <h5>II – possibilitem a revisão detalhada do conteúdo gerado e dos dados utilizados para sua elaboração, assegurando que os usuários tenham acesso às premissas e ao método empregado pela inteligência artificial na sua formulação, sem que haja qualquer espécie de vinculação à solução apresentada pela inteligência artificial e garantindo-se a possibilidade de correções ou ajustes.</h5>
      <h4>Parágrafo único. Em nenhum momento o sistema de IA poderá restringir ou substituir a autoridade final dos usuários internos.</h4>
      <h3>Art. 33. Os usuários externos deverão ser informados, de maneira clara, acessível e objetiva, sobre a utilização de sistemas baseados em IA nos serviços que lhes forem prestados, devendo ser empregada linguagem simples, que possibilite a fácil compreensão por parte de pessoas não especializadas.</h3>
      <h4>§ 1º A informação prevista no caput deste artigo deverá destacar o caráter consultivo e não vinculante da proposta de solução apresentada pela inteligência artificial, a qual sempre será submetida à análise e decisão final de uma autoridade competente, que exercerá a supervisão humana sobre o caso.</h4>
      <h4>§ 2º A comunicação sobre o uso de IA deverá ser realizada por meio de canais adequados, como avisos nos sistemas utilizados, materiais informativos e guias explicativos, com o intuito de orientar os usuários externos sobre o funcionamento, limitações e objetivos dos sistemas inteligentes no Judiciário.</h4>
      <h4>§ 3º A comunicação sobre o eventual uso da IA no texto de decisões judiciais será uma faculdade de seu signatário, observado o disposto no inciso IV do § 3º e o § 6º do art. 19 desta Resolução.</h4>
      <h4>§ 4º Os tribunais deverão disponibilizar periodicamente materiais educativos que ajudem os usuários externos a compreenderem o uso de IA nos processosjudiciais, esclarecendo que tais sistemas têm papel de suporte, sem substituir a autoridade decisória humana.</h4>
      <h3>Art. 34. Os sistemas computacionais utilizados no âmbito do Poder Judiciário deverão exigir a supervisão humana e permitir a modificação pelo magistrado competente de qualquer produto gerado pela inteligência artificial, sempre que cabível, observado o art. 32 desta Resolução.</h3>
      <h2>CAPÍTULO X DA PESQUISA, DO DESENVOLVIMENTO E DA IMPLANTAÇÃO DE SERVIÇOS DE INTELIGÊNCIA ARTIFICIAL</h2>
      <h3>Art. 35. A composição de equipes para pesquisa, desenvolvimento e implantação das soluções computacionais que se utilizem de inteligência artificial será orientada pela busca da diversidade e representatividade, com ênfase na inclusão, sempre que possível, de diferentes perfis de gênero e etnia e pessoas com deficiência, bem como de experiências e formação em áreas de conhecimento diversas.</h3>
      <h4>§ 1º A participação representativa deverá ser assegurada, tanto quanto possível, nas etapas de planejamento, coleta e processamento de dados, construção, verificação, validação e implementação dos modelos, tanto nas áreas técnicas como negociais.</h4>
      <h4>§ 2º A diversidade na participação prevista no caput deste artigo poderá ser dispensada mediante decisão fundamentada, dentre outros motivos, pela ausência de profissionais no quadro de pessoal dos tribunais ou a necessidade de garantir eficácia e a velocidade na implementação das soluções a curto prazo.</h4>
      <h4>§ 3º A formação das equipes mencionadas no caput deverá ter caráter interdisciplinar, incluindo profissionais de Tecnologia da Informação, do Direito e de outras áreas relevantes, cujo conhecimento científico possa contribuir para pesquisa, desenvolvimento ou implantação do sistema inteligente no tribunal.</h4>
      <h3>Art. 36. A realização de estudos, pesquisas, ensino e treinamentos de inteligência artificial deve ser livre de preconceitos, devendo para tanto:</h3>
      <h5>I – respeitar a dignidade e a liberdade de pessoas ou grupos envolvidos em suas atividades, evitando práticas de discriminação, assédio ou exclusão;</h5>
      <h5>II – coibir atividades que envolvam qualquer forma de risco ou prejuízo aos seres humanos, como testes inseguros ou a manipulação de dados sensíveis sem consentimento, ou ainda o uso indiscriminado ou malicioso de dados que possam comprometer a equidade das decisões; e</h5>
      <h5>III – identificar e evitar sectarismos ou vieses que possam direcionar o curso da pesquisa ou seus resultados, comprometendo a objetividade ou a imparcialidade dos estudos.</h5>
      <h3>Art. 37. Concluída a pesquisa e iniciado o desenvolvimento de soluções que utilizem modelos de inteligência artificial, os tribunais deverão cadastrar a iniciativa no Sinapses, na forma do art. 23 desta Resolução, e velar por sua continuidade enquanto for útil à execução das suas atividades.</h3>
      <h4>§ 1º As atividades descritas no caput deste artigo serão encerradas quando, mediante manifestação fundamentada, for reconhecida sua desconformidade com os preceitos estabelecidos nesta Resolução ou em outros atos normativos aplicáveis ao Poder Judiciário e for inviável sua readequação.</h4>
      <h4>§ 2º A utilização de modelos de inteligência artificial que empreguem técnicas de reconhecimento facial ou de análise biométrica que configurem aplicações de alto risco, nos termos do Anexo de Classificação de Risco, item AR5, requererá autorização prévia do Comitê Nacional de Inteligência Artificial do Judiciário para o seu desenvolvimento e implementação, sendo imprescindível a apresentação de um plano quecomprove a conformidade com os direitos fundamentais, a proteção de dados pessoais e o tratamento de potenciais vieses discriminatórios, em especial quanto à raça, condição social ou localidade geográfica de moradia.</h4>
      <h3>Art. 38. Os modelos de inteligência artificial poderão utilizar ferramentas de mercado ou soluções de código aberto que:</h3>
      <h5>I – facilitem sua integração ou interoperabilidade entre os sistemas utilizados pelos órgãos do Poder Judiciário, permitindo uma troca de informações eficiente e segura;</h5>
      <h5>II – possibilitem um ambiente de desenvolvimento colaborativo, no qual diferentes tribunais e instituições possam contribuir para evolução das soluções adequadas;</h5>
      <h5>III – permitam maior transparência, garantindo que os processos e algoritmos utilizados sejam acessíveis para auditoria, monitoramento e revisão por parte de especialistas autorizados ou por meio da sociedade civil, mediante requerimento;</h5>
      <h5>IV – proporcionem cooperação entre outros segmentos e áreas do setor público e a sociedade civil, promovendo iniciativas conjuntas para o desenvolvimento e a implementação de soluções de inteligência artificial;</h5>
      <h5>V – assegurem a proteção e a segurança dos dados utilizados, em particular os dados por cuja guarda o Poder Judiciário seja responsável, adotando medidas que previnam acessos não autorizados e preservem a integridade das informações; e</h5>
      <h5>VI – garantam a não-dependência tecnológica.</h5>
      <h2>CAPÍTULO XI DA AUDITORIA E DO MONITORAMENTO</h2>
      <h3>Art. 39. Qualquer solução computacional do Poder Judiciário que utilize modelos de inteligência artificial deverá assegurar total transparência na prestação de contas, com o objetivo de garantir um impacto positivo para os usuários finais e para a sociedade.</h3>
      <h4>§ 1º A prestação de contas compreenderá:</h4>
      <h5>I – os nomes dos responsáveis pela execução das ações e pela prestação de contas;</h5>
      <h5>II – os custos envolvidos na pesquisa, desenvolvimento, implantação, comunicação e treinamento;</h5>
      <h5>III – a existência de ações de colaboração e cooperação entre os agentes do setor público ou entre esses e a iniciativa privada ou a sociedade civil;</h5>
      <h5>IV – os resultados pretendidos e os que foram efetivamente alcançados;</h5>
      <h5>V – a demonstração de efetiva publicidade quanto à natureza do serviço oferecido, técnicas utilizadas, desempenho do sistema e riscos de erros; e</h5>
      <h5>VI – a demonstração da divulgação das informações acima mencionadas em formato acessível e linguagem simples, através de canais adequados, com atualizações regulares, permitindo a interação do público para esclarecimento de dúvidas e sugestões.</h5>
      <h4>§ 2º A prestação de contas deverá ser publicada em canal oficial e poderá ser submetida a auditoria externa por decisão do Tribunal ou do Comitê Nacional de Inteligência Artificial do Judiciário, quando for o caso.</h4>
      <h3>Art. 40. O desenvolvimento ou a utilização de sistemas inteligentes em desacordo com os princípios e regras estabelecidos nesta Resolução e nos demais normativos aplicáveis será monitorado, sem caráter disciplinar, por parte do Comitê Nacional de Inteligência Artificial do Judiciário.</h3>
      <h4>Parágrafo único. O monitoramento poderá indicar necessidade de auditoria sobre práticas inadequadas, uso indevido de dados e falta de transparência, e as desconformidades ou discrepâncias eventualmente identificadas poderão ser comunicadas pelo Comitê ao órgão competente para adoção de providências.</h4>
      <h3>Art. 41. O Comitê Nacional de Inteligência Artificial do Judiciário estabelecerá protocolo de auditoria e monitoramento para modelos e soluções de inteligência artificial em uso no Poder Judiciário.</h3>
      <h4>§ 1º A definição da metodologia para a condução de auditorias será realizada pelo Comitê, levando em consideração a identificação dos riscos envolvidos, a definição de salvaguardas (medidas de proteção) e a documentação produzida.</h4>
      <h4>§ 2º Para execução das atividades de auditoria e inspeção, o Comitê poderá propor à Presidência do CNJ a criação de comissões técnicas ou grupos de trabalho, que deverão contar com membros qualificados e com experiência nas áreas relacionadas à auditoria de inteligência artificial.</h4>
      <h4>§ 3º O monitoramento consistirá em um conjunto simplificado de análise, verificação e adoção de boas práticas de gestão de dados, processos e produtos, a fim de verificar a regularidade do funcionamento da solução baseada em IA e a manutenção de sua conformidade com as diretrizes desta Resolução.</h4>
      <h4>§ 4º Havendo identificação de desconformidades, o Comitê fixará prazo para correção, que será definido com base na gravidade e impactos da desconformidade.</h4>
      <h3>Art. 42. Os órgãos do Poder Judiciário deverão informar ao Comitê Nacional de Inteligência Artificial do Judiciário todos os eventos adversos relacionados ao uso de soluções de inteligência artificial.</h3>
      <h4>§ 1º Consideram-se eventos adversos os incidentes que resultem em impactos negativos sobre a operação do sistema, a segurança dos dados ou a prestação de serviços.</h4>
      <h4>§ 2º A comunicação dos eventos adversos deverá ser realizada no prazo de até 72 (setenta e duas) horas após a sua identificação, contendo descrição do incidente, suas causas e as medidas adotadas para correção.</h4>
      <h4>§ 3º O Comitê analisará as informações recebidas e poderá recomendar ações corretivas, conforme necessário.</h4>
      <h2>CAPÍTULO XII DAS DISPOSIÇÕES FINAIS</h2>
      <h3>Art. 43. Os órgãos do Poder Judiciário poderão realizar cooperação técnica com outras instituições, públicas ou privadas, ou com a sociedade civil, para o desenvolvimento colaborativo de modelos de inteligência artificial, desde que observadas as disposições contidas nesta Resolução.</h3>
      <h4>§ 1º A cooperação técnica deve incluir a elaboração de acordos que especifiquem as responsabilidades de cada parte no que diz respeito à proteção de dados e à confidencialidade das informações compartilhadas.</h4>
      <h4>§ 2º As instituições parceiras devem garantir que os dados utilizados na colaboração atendam aos requisitos da Lei Geral de Proteção de Dados Pessoais e às normas de segurança estabelecidas pelo Conselho Nacional de Justiça.</h4>
      <h4>§ 3º As soluções de IA do Judiciário devem ser desenvolvidas com a perspectiva de disponibilização de seus aplicativos na PDPJ-Br, ainda que por meio de versão adaptada para as peculiaridades técnicas da Plataforma.</h4>
      <h3>Art. 44. As normas previstas nesta Resolução não excluem a aplicação de outras normas do ordenamento jurídico brasileiro, incluindo, mas não se limitando a leis federais, estaduais e municipais, assim como tratados e convenções internacionais ratificados pela República Federativa do Brasil.</h3>
      <h3>Art. 45. As disposições desta Resolução aplicam-se também aos projetos e modelos de inteligência artificial já em desenvolvimento ou implantados nos tribunais, respeitados os atos já consolidados.</h3>
      <h4>Parágrafo único. Os tribunais terão um prazo de 12 (doze) meses para adequar seus projetos e modelos, em desenvolvimento ou já implantados, às novas disposições estabelecidas nesta Resolução, a partir de sua publicação.</h4>
      <h3>Art. 46. Revoga-se a Resolução CNJ nº 332/2020 , a partir do início da vigência desta Resolução.</h3>
      <h3>Art. 47. Esta Resolução entra em vigor após decorridos 120 (cento e vinte) dias da data de sua publicação.</h3>
      <p>Ministro Luís Roberto Barroso</p>
      <h6>ANEXO DA RESOLUÇÃO Nº 615, DE 11 DE MARÇO DE 2025. CLASSIFICAÇÃO DE RISCOS</h6>
      <p>Consideram-se de alto risco as seguintes finalidades e contextos para o desenvolvimento de soluções baseadas em inteligência artificial destinadas a desempenhar ou apoiar o usuário na realização das seguintes atividades acessórias:</p>
      <h6>AR1 – identificação de perfis e de padrões comportamentais de pessoas naturais ou de grupos de pessoas naturais, exceto quando enquadradas como situações de risco mínimo ou controlado, conforme critérios objetivos estabelecidos;</h6>
      <h6>AR2 – aferição da adequação dos meios de prova e a sua valoração nos processos de jurisdição contenciosa, sejam documentais, testemunhais, periciais ou de outras naturezas, especialmente quando tais avaliações possam influenciar diretamente a decisão judicial;</h6>
      <h6>AR3 – averiguação, valoração, tipificação e a interpretação de fatos como sendo crimes, contravenções penais ou atos infracionais, ressalvadas as soluções voltadas à mera rotina da execução penal e de medidas socioeducativas;</h6>
      <h6>AR4 – formulação de juízos conclusivos sobre a aplicação da norma jurídica ou precedentes a um conjunto determinado de fatos concretos, inclusive para a quantificação ou a qualificação de danos suportados por pessoas ou grupos, em ações criminais ou não;</h6>
      <h6>AR5 – identificação e a autenticação facial ou biométrica para o monitoramento de comportamento de pessoas naturais, exceto quando utilizada para a mera confirmação da identidade de uma pessoa natural específica ou para atividades de segurança pública devidamente justificadas, sempre garantida a observância dos direitos fundamentais e monitoramento contínuo de tais soluções.</h6>
      <p>Consideram-se de baixo risco as seguintes finalidades e contextos para o desenvolvimento de soluções baseadas em inteligência artificial destinadas a desempenhar ou apoiar o usuário na realização das seguintes atividades acessórias:</p>
      <h6>BR1 – execução de atos processuais ordinatórios ou de tarefas de apoio à administração judiciária, mediante a extração de informações de sistemas e de documentos, com a finalidade de classificação e agrupamento de dados e processos, enriquecimento de cadastros, certificação e transcrição de atos processuais, sumarização ou resumo de documentos, entre outras finalidades de gestão processual e operacional, desde que supervisionadas por responsável humano;</h6>
      <h6>BR2 – detecção de padrões decisórios ou de desvios de padrões decisórios, bem como detecção de precedentes qualificados pertinentes, observado o caráter complementar da técnica de inteligência artificial, desde que não haja substituição da avaliação humana sobre processos, sendo seu uso destinado para apoio interno ao tribunal e para uniformização da jurisprudência;</h6>
      <h6>BR3 – fornecimento aos magistrados de subsídios para a tomada de decisão mediante relatórios gerenciais e análises que adotem técnica jurimétrica, com a integração de fontes de informação relevantes ou a detecção de padrões decisórios, desde que não haja substituição da avaliação humana e que a solução não realize valorações de cunho moral sobre provas ou sobre perfis e condutas de pessoas;</h6>
      <h6>BR4 – produção de textos de apoio para facilitar a confecção de atos judiciais, desde que a supervisão e a versão final do documento sejam realizadas pelo magistrado e com base em suas instruções, especialmente as decisões acerca das preliminares e questões de mérito;</h6>
      <h6>BR5 – aprimoramento ou formatação de uma atividade humana anteriormente realizada, desde que não se altere materialmente o seu resultado, ou ainda realização de uma tarefa preparatória para uma outra, considerada como de alto risco;</h6>
      <h6>BR6 – realização de análises estatísticas para fins de política judiciária, sempre com supervisão humana contínua, especialmente para evitar conclusões enviesadas;</h6>
      <h6>BR7 – transcrição de áudio e vídeo para o auxílio das atividades do magistrado, com revisão final realizada por pessoa responsável;</h6>
      <h6>BR8 – anonimização de documentos ou de sua exibição, especialmente para garantir sua conformidade com as normas de privacidade e proteção de dados.</h6>
    </article>

    <footer>
      <p class="disclaimer">
        <strong>Aviso Legal:</strong> Este é um espelho não oficial para fins técnicos de ingestão por agentes de IA. 
        O conteúdo oficial e juridicamente válido está disponível no 
        <a href="https://atos.cnj.jus.br/atos/detalhar/6001" rel="nofollow" target="_blank">CNJ – Atos Normativos</a> 
        e no Diário da Justiça Eletrônico.
      </p>
    </footer>
  </main>
</body>
</html>